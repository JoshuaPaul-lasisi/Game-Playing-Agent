{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  top-left top-middle top-right middle-left middle-middle middle-right  \\\n",
      "0        x          x         x           x             o            o   \n",
      "1        x          x         x           x             o            o   \n",
      "2        x          x         x           x             o            o   \n",
      "3        x          x         x           x             o            o   \n",
      "4        x          x         x           x             o            o   \n",
      "\n",
      "  bottom-left bottom-middle bottom-right   outcome  \n",
      "0           x             o            o  positive  \n",
      "1           o             x            o  positive  \n",
      "2           o             o            x  positive  \n",
      "3           o             b            b  positive  \n",
      "4           b             o            b  positive  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"../data/tic-tac-toe.data\", header=None)\n",
    "data.columns = [\n",
    "    \"top-left\", \"top-middle\", \"top-right\",\n",
    "    \"middle-left\", \"middle-middle\", \"middle-right\",\n",
    "    \"bottom-left\", \"bottom-middle\", \"bottom-right\",\n",
    "    \"outcome\"\n",
    "]\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data:\n",
      "[[ 1  1  1  1 -1 -1  1 -1 -1]\n",
      " [ 1  1  1  1 -1 -1 -1  1 -1]\n",
      " [ 1  1  1  1 -1 -1 -1 -1  1]\n",
      " [ 1  1  1  1 -1 -1 -1  0  0]\n",
      " [ 1  1  1  1 -1 -1  0 -1  0]] [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Encode the data\n",
    "mapping = {'x': 1, 'o': -1, 'b': 0, 'positive': 1, 'negative': 0}\n",
    "data = data.replace(mapping).infer_objects(copy=False)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "print(\"Processed data:\")\n",
    "print(X[:5], y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TicTacToeEnv:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)  # Empty board\n",
    "        self.done = False\n",
    "        self.winner = None\n",
    "        return self.board\n",
    "\n",
    "    def step(self, action, player):\n",
    "        # action is the index (0-8), player is 1 (agent) or -1 (opponent)\n",
    "        row, col = divmod(action, 3)\n",
    "        if self.board[row, col] != 0:\n",
    "            return self.board, -10, True  # Invalid move penalty\n",
    "        self.board[row, col] = player\n",
    "\n",
    "        if self.check_winner(player):\n",
    "            self.done = True\n",
    "            self.winner = player\n",
    "            return self.board, 1 if player == 1 else -1, True  # Reward for winning\n",
    "\n",
    "        if not np.any(self.board == 0):  # Draw condition\n",
    "            self.done = True\n",
    "            self.winner = 0\n",
    "            return self.board, 0, True\n",
    "\n",
    "        return self.board, 0, False  # No reward, game continues\n",
    "\n",
    "    def check_winner(self, player):\n",
    "        for row in self.board:\n",
    "            if np.all(row == player):\n",
    "                return True\n",
    "        for col in self.board.T:\n",
    "            if np.all(col == player):\n",
    "                return True\n",
    "        if np.all(np.diag(self.board) == player) or np.all(np.diag(np.fliplr(self.board)) == player):\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, learning_rate=0.1, discount_factor=0.95, epsilon=1.0, epsilon_decay=0.99):\n",
    "        self.q_table = {}\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_table.get((tuple(state.flatten()), action), 0)\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        max_next_q = max([self.get_q_value(next_state, a) for a in range(9)])\n",
    "        current_q = self.get_q_value(state, action)\n",
    "        self.q_table[(tuple(state.flatten()), action)] = current_q + self.lr * (reward + self.gamma * max_next_q - current_q)\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, 8)  # Explore\n",
    "        q_values = [self.get_q_value(state, a) for a in range(9)]\n",
    "        return np.argmax(q_values)  # Exploit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_opponent(board):\n",
    "    \"\"\"Random opponent selects a random valid action.\"\"\"\n",
    "    valid_actions = [i for i in range(9) if board.flatten()[i] == 0]\n",
    "    return random.choice(valid_actions) if valid_actions else None\n",
    "\n",
    "def evaluate_agent(agent, env, num_games=100, opponent=\"random\"):\n",
    "    results = {\"wins\": 0, \"losses\": 0, \"draws\": 0}\n",
    "    for _ in range(num_games):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        player_turn = 1  # Agent starts first\n",
    "\n",
    "        while not done:\n",
    "            if player_turn == 1:  # Agent's turn\n",
    "                action = agent.select_action(state)\n",
    "            else:  # Opponent's turn\n",
    "                if opponent == \"random\":\n",
    "                    action = random_opponent(state)\n",
    "                elif opponent == \"rule\":\n",
    "                    action = rule_based_opponent(state)  # Add rule-based logic\n",
    "\n",
    "            if action is None:  # No valid moves, game over\n",
    "                break\n",
    "\n",
    "            _, reward, done = env.step(action, player_turn)\n",
    "            player_turn *= -1  # Alternate turns\n",
    "\n",
    "        # Record results\n",
    "        if env.winner == 1:\n",
    "            results[\"wins\"] += 1\n",
    "        elif env.winner == -1:\n",
    "            results[\"losses\"] += 1\n",
    "        else:\n",
    "            results[\"draws\"] += 1\n",
    "\n",
    "    print(f\"Evaluation Results: {results}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
